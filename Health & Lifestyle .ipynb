{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56523ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "d:\\practice python\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in .\\venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in .\\venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in .\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in .\\venv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in .\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in .\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in .\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in .\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nitesh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in .\\venv\\lib\\site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in .\\venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in .\\venv\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nitesh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in .\\venv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in .\\venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in .\\venv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in .\\venv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in .\\venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in .\\venv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\nitesh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.3.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in .\\venv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in .\\venv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in .\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in .\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in .\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in .\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in .\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in .\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in .\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in .\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in .\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in .\\venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nitesh\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in .\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.8125 - loss: 0.4640 - val_accuracy: 0.9350 - val_loss: 0.2586\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3443 - val_accuracy: 0.9350 - val_loss: 0.2574\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9000 - loss: 0.3310 - val_accuracy: 0.9350 - val_loss: 0.2643\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.3169 - val_accuracy: 0.9350 - val_loss: 0.2624\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.3114 - val_accuracy: 0.9350 - val_loss: 0.2628\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3082 - val_accuracy: 0.9350 - val_loss: 0.2696\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.3027 - val_accuracy: 0.9350 - val_loss: 0.2676\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9000 - loss: 0.2985 - val_accuracy: 0.9350 - val_loss: 0.2705\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9000 - loss: 0.2926 - val_accuracy: 0.9350 - val_loss: 0.2698\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.2895 - val_accuracy: 0.9350 - val_loss: 0.2702\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9000 - loss: 0.2796 - val_accuracy: 0.9350 - val_loss: 0.2719\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9000 - loss: 0.2746 - val_accuracy: 0.9350 - val_loss: 0.2759\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9013 - loss: 0.2691 - val_accuracy: 0.9350 - val_loss: 0.2747\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9013 - loss: 0.2647 - val_accuracy: 0.9350 - val_loss: 0.2798\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9000 - loss: 0.2557 - val_accuracy: 0.9350 - val_loss: 0.2781\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9038 - loss: 0.2544 - val_accuracy: 0.9300 - val_loss: 0.2861\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9038 - loss: 0.2510 - val_accuracy: 0.9350 - val_loss: 0.2843\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9050 - loss: 0.2489 - val_accuracy: 0.9300 - val_loss: 0.2894\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9075 - loss: 0.2398 - val_accuracy: 0.9300 - val_loss: 0.2895\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9050 - loss: 0.2234 - val_accuracy: 0.9300 - val_loss: 0.2941\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9162 - loss: 0.2171 - val_accuracy: 0.9250 - val_loss: 0.3081\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9087 - loss: 0.2191 - val_accuracy: 0.9100 - val_loss: 0.3237\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9175 - loss: 0.2101 - val_accuracy: 0.9300 - val_loss: 0.2954\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9212 - loss: 0.1959 - val_accuracy: 0.9100 - val_loss: 0.3148\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9212 - loss: 0.1835 - val_accuracy: 0.9250 - val_loss: 0.3102\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9200 - loss: 0.1872 - val_accuracy: 0.8950 - val_loss: 0.3384\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9287 - loss: 0.1846 - val_accuracy: 0.9300 - val_loss: 0.3065\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.1733 - val_accuracy: 0.9100 - val_loss: 0.3218\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9262 - loss: 0.1700 - val_accuracy: 0.8900 - val_loss: 0.3414\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.1623 - val_accuracy: 0.9000 - val_loss: 0.3388\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9362 - loss: 0.1588 - val_accuracy: 0.9000 - val_loss: 0.3403\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9400 - loss: 0.1533 - val_accuracy: 0.9000 - val_loss: 0.3466\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9513 - loss: 0.1314 - val_accuracy: 0.9050 - val_loss: 0.3402\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9513 - loss: 0.1437 - val_accuracy: 0.8950 - val_loss: 0.3549\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9463 - loss: 0.1321 - val_accuracy: 0.9050 - val_loss: 0.3545\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9475 - loss: 0.1283 - val_accuracy: 0.8950 - val_loss: 0.3705\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9475 - loss: 0.1319 - val_accuracy: 0.9050 - val_loss: 0.3727\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9525 - loss: 0.1310 - val_accuracy: 0.9000 - val_loss: 0.3655\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9513 - loss: 0.1113 - val_accuracy: 0.9000 - val_loss: 0.3769\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9613 - loss: 0.1118 - val_accuracy: 0.8950 - val_loss: 0.3987\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9563 - loss: 0.1213 - val_accuracy: 0.8950 - val_loss: 0.3902\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9638 - loss: 0.1076 - val_accuracy: 0.8800 - val_loss: 0.4095\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9575 - loss: 0.1036 - val_accuracy: 0.9050 - val_loss: 0.3797\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9663 - loss: 0.0964 - val_accuracy: 0.8950 - val_loss: 0.3828\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9663 - loss: 0.0977 - val_accuracy: 0.9050 - val_loss: 0.3948\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9613 - loss: 0.1009 - val_accuracy: 0.8500 - val_loss: 0.4432\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9625 - loss: 0.1027 - val_accuracy: 0.8850 - val_loss: 0.4170\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9725 - loss: 0.0856 - val_accuracy: 0.8850 - val_loss: 0.4251\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9725 - loss: 0.0814 - val_accuracy: 0.8850 - val_loss: 0.4147\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9725 - loss: 0.0899 - val_accuracy: 0.8950 - val_loss: 0.4078\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9720 - loss: 0.1184\n",
      "\n",
      "Model Accuracy: 97.20%\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"D:\\\\practice python\\\\1-python Basics\\\\health_activity_data.csv\")\n",
    "\n",
    "data = data.drop('ID', axis=1)\n",
    "\n",
    "y = data['Heart_Disease']\n",
    "X = data.drop('Heart_Disease', axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "categorical_cols = ['Gender', 'Smoker', 'Alcohol_Consumption_per_Week', 'Diabetic']\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_processed.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_processed, y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_processed, y)\n",
    "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0fbee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Daily_Steps</th>\n",
       "      <th>Calories_Intake</th>\n",
       "      <th>Hours_of_Sleep</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Exercise_Hours_per_Week</th>\n",
       "      <th>Alcohol_Consumption_per_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.857000</td>\n",
       "      <td>174.74500</td>\n",
       "      <td>84.35200</td>\n",
       "      <td>26.729510</td>\n",
       "      <td>10717.034000</td>\n",
       "      <td>2327.117000</td>\n",
       "      <td>6.90990</td>\n",
       "      <td>84.710000</td>\n",
       "      <td>5.045500</td>\n",
       "      <td>4.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.114267</td>\n",
       "      <td>14.54192</td>\n",
       "      <td>20.06596</td>\n",
       "      <td>4.786341</td>\n",
       "      <td>5444.707891</td>\n",
       "      <td>657.847942</td>\n",
       "      <td>1.77964</td>\n",
       "      <td>20.130155</td>\n",
       "      <td>2.847801</td>\n",
       "      <td>2.852509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>150.00000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>162.00000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>6028.250000</td>\n",
       "      <td>1745.750000</td>\n",
       "      <td>5.30000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.675000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>175.00000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>10898.000000</td>\n",
       "      <td>2328.500000</td>\n",
       "      <td>6.90000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>30.850000</td>\n",
       "      <td>15253.250000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>199.00000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>34.980000</td>\n",
       "      <td>19931.000000</td>\n",
       "      <td>3498.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age   Height_cm   Weight_kg          BMI   Daily_Steps  \\\n",
       "count  1000.000000  1000.00000  1000.00000  1000.000000   1000.000000   \n",
       "mean     49.857000   174.74500    84.35200    26.729510  10717.034000   \n",
       "std      18.114267    14.54192    20.06596     4.786341   5444.707891   \n",
       "min      18.000000   150.00000    50.00000    18.500000   1016.000000   \n",
       "25%      35.000000   162.00000    68.00000    22.600000   6028.250000   \n",
       "50%      50.000000   175.00000    84.00000    26.800000  10898.000000   \n",
       "75%      66.000000   187.00000   101.00000    30.850000  15253.250000   \n",
       "max      79.000000   199.00000   119.00000    34.980000  19931.000000   \n",
       "\n",
       "       Calories_Intake  Hours_of_Sleep   Heart_Rate  Exercise_Hours_per_Week  \\\n",
       "count      1000.000000      1000.00000  1000.000000              1000.000000   \n",
       "mean       2327.117000         6.90990    84.710000                 5.045500   \n",
       "std         657.847942         1.77964    20.130155                 2.847801   \n",
       "min        1201.000000         4.00000    50.000000                 0.000000   \n",
       "25%        1745.750000         5.30000    67.000000                 2.675000   \n",
       "50%        2328.500000         6.90000    84.000000                 5.100000   \n",
       "75%        2880.000000         8.40000   103.000000                 7.600000   \n",
       "max        3498.000000        10.00000   119.000000                10.000000   \n",
       "\n",
       "       Alcohol_Consumption_per_Week  \n",
       "count                   1000.000000  \n",
       "mean                       4.573000  \n",
       "std                        2.852509  \n",
       "min                        0.000000  \n",
       "25%                        2.000000  \n",
       "50%                        5.000000  \n",
       "75%                        7.000000  \n",
       "max                        9.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c6dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9391 - loss: 0.1881 - val_accuracy: 0.9625 - val_loss: 0.1338\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9453 - loss: 0.1514 - val_accuracy: 0.9625 - val_loss: 0.1365\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9609 - loss: 0.1239 - val_accuracy: 0.9312 - val_loss: 0.1441\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9594 - loss: 0.1290 - val_accuracy: 0.9312 - val_loss: 0.1647\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.1058 - val_accuracy: 0.9375 - val_loss: 0.1628\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9672 - loss: 0.1021 - val_accuracy: 0.9312 - val_loss: 0.1698\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9609 - loss: 0.1064 - val_accuracy: 0.9312 - val_loss: 0.1778\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9656 - loss: 0.1085 - val_accuracy: 0.9312 - val_loss: 0.1712\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9719 - loss: 0.0902 - val_accuracy: 0.9250 - val_loss: 0.1891\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9703 - loss: 0.0843 - val_accuracy: 0.9250 - val_loss: 0.1784\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9750 - loss: 0.0758 - val_accuracy: 0.9250 - val_loss: 0.1948\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9656 - loss: 0.0844 - val_accuracy: 0.9312 - val_loss: 0.1876\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0746 - val_accuracy: 0.9125 - val_loss: 0.2216\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9734 - loss: 0.0744 - val_accuracy: 0.9187 - val_loss: 0.1964\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9766 - loss: 0.0727 - val_accuracy: 0.9312 - val_loss: 0.1927\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9750 - loss: 0.0637 - val_accuracy: 0.9312 - val_loss: 0.1992\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0726 - val_accuracy: 0.9250 - val_loss: 0.2133\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9766 - loss: 0.0664 - val_accuracy: 0.9125 - val_loss: 0.2202\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0531 - val_accuracy: 0.9187 - val_loss: 0.2258\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0546 - val_accuracy: 0.9125 - val_loss: 0.2350\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.0495 - val_accuracy: 0.9125 - val_loss: 0.2555\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9797 - loss: 0.0511 - val_accuracy: 0.9250 - val_loss: 0.2311\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9812 - loss: 0.0531 - val_accuracy: 0.9125 - val_loss: 0.2692\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0514 - val_accuracy: 0.9187 - val_loss: 0.2559\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9812 - loss: 0.0573 - val_accuracy: 0.9187 - val_loss: 0.2730\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.0496 - val_accuracy: 0.9125 - val_loss: 0.2660\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0463 - val_accuracy: 0.9125 - val_loss: 0.2785\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0455 - val_accuracy: 0.9125 - val_loss: 0.2708\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9875 - loss: 0.0398 - val_accuracy: 0.9125 - val_loss: 0.2811\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0419 - val_accuracy: 0.9187 - val_loss: 0.2736\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0356 - val_accuracy: 0.9187 - val_loss: 0.2977\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0420 - val_accuracy: 0.9187 - val_loss: 0.2762\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0317 - val_accuracy: 0.9125 - val_loss: 0.2950\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0346 - val_accuracy: 0.9062 - val_loss: 0.2997\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9937 - loss: 0.0338 - val_accuracy: 0.9125 - val_loss: 0.3112\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0315 - val_accuracy: 0.9187 - val_loss: 0.2931\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9922 - loss: 0.0313 - val_accuracy: 0.9187 - val_loss: 0.3037\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0383 - val_accuracy: 0.9187 - val_loss: 0.3157\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0320 - val_accuracy: 0.9187 - val_loss: 0.3091\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0335 - val_accuracy: 0.9187 - val_loss: 0.3302\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0372 - val_accuracy: 0.9187 - val_loss: 0.3237\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0241 - val_accuracy: 0.9187 - val_loss: 0.3387\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 0.0213 - val_accuracy: 0.9187 - val_loss: 0.3405\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0349 - val_accuracy: 0.9125 - val_loss: 0.3583\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9969 - loss: 0.0251 - val_accuracy: 0.9125 - val_loss: 0.3529\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0276 - val_accuracy: 0.9250 - val_loss: 0.3114\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0285 - val_accuracy: 0.9125 - val_loss: 0.3699\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9922 - loss: 0.0282 - val_accuracy: 0.9187 - val_loss: 0.3367\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9922 - loss: 0.0291 - val_accuracy: 0.9250 - val_loss: 0.3549\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0273 - val_accuracy: 0.9125 - val_loss: 0.3699\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Precision: 33.33%\n",
      "Recall: 14.29%\n",
      "F1‑Score: 20.00%\n"
     ]
    }
   ],
   "source": [
    "# After preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Add train‑test split (e.g., 80‑20)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now fit the model using training set\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Compute metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1‑Score: {f1 * 100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
